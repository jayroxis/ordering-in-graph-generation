
# ====================== Data Configs =========================

class: VisionSequenceModel

data:
  name: PlanarGraphDataset
  class: StandardDataModule

  train_set:
    class: CircuitSignalToRawFeaturesDataset
    params:
      data_file: archived/circuit_data/train_preprocessed.pkl
      sort_func: mean_square_sort

  train_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 100     # effective batch size = batch_size * num_gpu
      num_workers: 16
      pin_memory: True
      shuffle: True
      collate_fn:
        class: PadSequenceConstant
        params:
          pad_value: -1.0

  val_set:
    class: CircuitSignalToRawFeaturesDataset
    params:
      data_file: archived/circuit_data/valid_preprocessed.pkl
      sort_func: mean_square_sort

  val_loader:
    class: torch.utils.data.DataLoader
    params:
      batch_size: 500     # effective batch size = batch_size * num_gpu
      num_workers: 8
      pin_memory: True
      shuffle: False
      collate_fn:
        class: PadSequenceConstant
        params:
          pad_value: -1.0

# ==================== Training Configs =========================
training:
  save_dir: ./runs/circuit
  optimizer:
    class: torch.optim.AdamW
    params:
      lr: 0.0002
      weight_decay: 0.0001

  scheduler:
    class: torch.optim.lr_scheduler.OneCycleLR
    params:
      max_lr: 0.0002
      total_steps: 200            # should be the same as training epochs
      pct_start: 0.05
      div_factor: 100.0
      final_div_factor: 10000.0
      anneal_strategy: 'cos'

  params:                   # arguments for PyTorch Lightning Trainer
    max_epochs: 200         # should be the same as training epochs
    accelerator: gpu
    precision: 32
    strategy: ddp_find_unused_parameters_false
    enable_checkpointing: True
    check_val_every_n_epoch: 1
    log_every_n_steps: 50
    
  train_metrics:
    l1_loss: 
      class: nn.L1Loss
      weight: 1.0
    mse_loss:
      class: nn.MSELoss
      weight: 1.0

  eval_metrics:
    l1_loss: 
      class: nn.L1Loss
      weight: 1.0
    mse_loss:
      class: nn.MSELoss
      weight: 1.0

# ====================== Model Configs =========================

model:
  name: ConditionalGraphGPT
  class: seq_gpt
  params:
    input_dim: 2
    output_dim: 9
    emb_dim: 512
    gpt_name: lstm_medium
    prompt_enc_name: MLPEncoder
    prompt_enc_cfg:
      hidden_dim: 256 
      num_layers: 2
    stop_detector_cfg:
      model_name: StopTokenDetectorFloat
      stop_value: -1.0
      threshold: 0.8

  ema_model:
    class: ModelEmaV2
    params: 
      decay: 0.995